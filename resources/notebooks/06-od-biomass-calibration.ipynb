{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f465058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368ed971",
   "metadata": {},
   "source": [
    "## 1. Load Synthetic Calibration Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23a0f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load synthetic OD timeseries dataset\n",
    "with open('resources/datasets/synthetic-od-timeseries-50-experiments.json', 'r') as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "print(f\"Dataset: {dataset['metadata']['dataset_id']}\")\n",
    "print(f\"Total experiments: {dataset['metadata']['data_composition']['calibration_experiments'] + dataset['metadata']['data_composition']['validation_experiments']}\")\n",
    "print(f\"\\nStrains: {list(dataset['dataset_statistics']['strain_distribution'].keys())}\")\n",
    "print(f\"Media types: {list(dataset['dataset_statistics']['media_distribution'].keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f90bc0a",
   "metadata": {},
   "source": [
    "## 2. Extract and Prepare Calibration Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35076128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract first experiment (WT + LB) for demonstration\n",
    "exp = dataset['experiment_samples'][0]\n",
    "\n",
    "print(f\"Experiment ID: {exp['experiment_id']}\")\n",
    "print(f\"Strain: {exp['strain_id']}\")\n",
    "print(f\"Medium: {exp['medium_type']}\")\n",
    "print(f\"Temperature: {exp['temperature_celsius']}°C\")\n",
    "print(f\"Sampling interval: {exp['sampling_interval_minutes']} minutes\")\n",
    "\n",
    "# Convert time-series to DataFrame\n",
    "data = []\n",
    "for point in exp['time_series']:\n",
    "    data.append({\n",
    "        'elapsed_hours': point['elapsed_hours'],\n",
    "        'od600': point['od600_measured'],\n",
    "        'dcw_g_per_l': point['dcw_g_per_l'],\n",
    "        'cell_count_million': point.get('cell_count_million', np.nan),\n",
    "        'viability_percent': point.get('viability_percent', np.nan)\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"\\nDataFrame shape: {df.shape}\")\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b0bba0",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a013425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"Summary Statistics:\")\n",
    "print(f\"OD600 range: {df['od600'].min():.3f} - {df['od600'].max():.3f}\")\n",
    "print(f\"DCW range: {df['dcw_g_per_l'].min():.3f} - {df['dcw_g_per_l'].max():.3f} g/L\")\n",
    "print(f\"\\nOD600 - DCW Correlation: {df['od600'].corr(df['dcw_g_per_l']):.4f}\")\n",
    "\n",
    "# Plot raw time-series\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "axes[0, 0].plot(df['elapsed_hours'], df['od600'], 'o-', label='OD600', color='blue')\n",
    "axes[0, 0].set_xlabel('Elapsed Time (hours)')\n",
    "axes[0, 0].set_ylabel('OD600')\n",
    "axes[0, 0].set_title('Optical Density Time Course')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].legend()\n",
    "\n",
    "axes[0, 1].plot(df['elapsed_hours'], df['dcw_g_per_l'], 's-', label='DCW', color='green')\n",
    "axes[0, 1].set_xlabel('Elapsed Time (hours)')\n",
    "axes[0, 1].set_ylabel('Dry Cell Weight (g/L)')\n",
    "axes[0, 1].set_title('Biomass Time Course')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "axes[0, 1].legend()\n",
    "\n",
    "axes[1, 0].scatter(df['od600'], df['dcw_g_per_l'], alpha=0.6, s=80, color='purple')\n",
    "axes[1, 0].set_xlabel('OD600')\n",
    "axes[1, 0].set_ylabel('DCW (g/L)')\n",
    "axes[1, 0].set_title('OD600 vs Biomass Relationship')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 1].plot(df['elapsed_hours'], df['viability_percent'], '^-', label='Viability', color='orange')\n",
    "axes[1, 1].set_xlabel('Elapsed Time (hours)')\n",
    "axes[1, 1].set_ylabel('Viability (%)')\n",
    "axes[1, 1].set_title('Cell Viability Time Course')\n",
    "axes[1, 1].set_ylim([90, 100])\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('resources/notebooks/od-biomass-eda.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"EDA plots generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6559e5",
   "metadata": {},
   "source": [
    "## 4. Growth Phase Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d319a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate growth rate (dOD/dt)\n",
    "df['dod_dt'] = df['od600'].diff() / df['elapsed_hours'].diff()\n",
    "df['d2od_dt2'] = df['dod_dt'].diff() / df['elapsed_hours'].diff()\n",
    "\n",
    "# Classify growth phases\n",
    "def classify_phase(row):\n",
    "    dod_dt = row['dod_dt']\n",
    "    if pd.isna(dod_dt) or dod_dt < 0.02:\n",
    "        return 'Lag'\n",
    "    elif dod_dt > 0.05:\n",
    "        return 'Exponential'\n",
    "    else:\n",
    "        return 'Transition'\n",
    "\n",
    "df['phase'] = df.apply(classify_phase, axis=1)\n",
    "\n",
    "# Summary by phase\n",
    "phase_summary = df.groupby('phase').agg({\n",
    "    'od600': ['min', 'max', 'mean'],\n",
    "    'dod_dt': 'mean',\n",
    "    'dcw_g_per_l': 'mean'\n",
    "})\n",
    "\n",
    "print(\"Growth Phase Summary:\")\n",
    "print(phase_summary)\n",
    "\n",
    "# Plot growth rate\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(df['elapsed_hours'], df['dod_dt'], 'o-', color='red', label='dOD/dt')\n",
    "ax.axhline(y=0.05, color='green', linestyle='--', label='Exponential threshold')\n",
    "ax.axhline(y=0.02, color='orange', linestyle='--', label='Lag threshold')\n",
    "ax.set_xlabel('Elapsed Time (hours)')\n",
    "ax.set_ylabel('Growth Rate (dOD/dt per hour)')\n",
    "ax.set_title('Growth Rate Profile')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.savefig('resources/notebooks/growth-rate-profile.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPhase classification complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89553e62",
   "metadata": {},
   "source": [
    "## 5. Linear Calibration Model (OLS Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7890c280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear model: DCW = a + b * OD600\n",
    "X = df[['od600']].values\n",
    "y = df['dcw_g_per_l'].values\n",
    "\n",
    "# Remove NaN values\n",
    "mask = ~(np.isnan(X.flatten()) | np.isnan(y))\n",
    "X_clean = X[mask]\n",
    "y_clean = y[mask]\n",
    "\n",
    "# Fit OLS\n",
    "model_linear = LinearRegression()\n",
    "model_linear.fit(X_clean, y_clean)\n",
    "\n",
    "# Model parameters\n",
    "intercept = model_linear.intercept_\n",
    "slope = model_linear.coef_[0]\n",
    "r2 = model_linear.score(X_clean, y_clean)\n",
    "\n",
    "# Calculate residuals\n",
    "y_pred_linear = model_linear.predict(X_clean)\n",
    "residuals = y_clean - y_pred_linear\n",
    "rmse = np.sqrt(np.mean(residuals**2))\n",
    "mae = np.mean(np.abs(residuals))\n",
    "\n",
    "# Calculate standard error\n",
    "n = len(X_clean)\n",
    "se_residuals = np.sqrt(np.sum(residuals**2) / (n - 2))\n",
    "\n",
    "print(f\"Linear Model: DCW = {intercept:.4f} + {slope:.4f} × OD600\")\n",
    "print(f\"R² = {r2:.4f}\")\n",
    "print(f\"RMSE = {rmse:.4f} g/L\")\n",
    "print(f\"MAE = {mae:.4f} g/L\")\n",
    "print(f\"Residual Std Error = {se_residuals:.4f}\")\n",
    "\n",
    "# Acceptance criteria check\n",
    "print(f\"\\nAcceptance Criteria:\")\n",
    "print(f\"  R² ≥ 0.90: {r2:.4f} {'✓ PASS' if r2 >= 0.90 else '✗ FAIL'}\")\n",
    "print(f\"  RMSE < 0.15 g/L: {rmse:.4f} {'✓ PASS' if rmse < 0.15 else '✗ FAIL'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a401b52",
   "metadata": {},
   "source": [
    "## 6. Surrogate Model (Gaussian Process Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991d85a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features: OD600, growth rate (dOD/dt), elapsed time\n",
    "df_gp = df.dropna(subset=['od600', 'dcw_g_per_l', 'dod_dt'])\n",
    "\n",
    "X_gp = df_gp[['od600', 'dod_dt', 'elapsed_hours']].values\n",
    "y_gp = df_gp['dcw_g_per_l'].values\n",
    "\n",
    "# Normalize features\n",
    "X_mean = X_gp.mean(axis=0)\n",
    "X_std = X_gp.std(axis=0)\n",
    "X_gp_norm = (X_gp - X_mean) / X_std\n",
    "\n",
    "# Fit Gaussian Process\n",
    "kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))\n",
    "model_gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, alpha=0.01)\n",
    "model_gp.fit(X_gp_norm, y_gp)\n",
    "\n",
    "# Predictions with uncertainty\n",
    "y_pred_gp, y_std_gp = model_gp.predict(X_gp_norm, return_std=True)\n",
    "\n",
    "# Model performance\n",
    "r2_gp = model_gp.score(X_gp_norm, y_gp)\n",
    "residuals_gp = y_gp - y_pred_gp\n",
    "rmse_gp = np.sqrt(np.mean(residuals_gp**2))\n",
    "\n",
    "print(f\"Gaussian Process Model:\")\n",
    "print(f\"R² = {r2_gp:.4f}\")\n",
    "print(f\"RMSE = {rmse_gp:.4f} g/L\")\n",
    "print(f\"Mean prediction uncertainty (std): {y_std_gp.mean():.4f} g/L\")\n",
    "print(f\"Max prediction uncertainty: {y_std_gp.max():.4f} g/L\")\n",
    "\n",
    "print(f\"\\nAcceptance Criteria:\")\n",
    "print(f\"  R² ≥ 0.92: {r2_gp:.4f} {'✓ PASS' if r2_gp >= 0.92 else '✗ FAIL'}\")\n",
    "print(f\"  RMSE < 0.12 g/L: {rmse_gp:.4f} {'✓ PASS' if rmse_gp < 0.12 else '✗ FAIL'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f2e083",
   "metadata": {},
   "source": [
    "## 7. Uncertainty Quantification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c54991f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate 95% prediction intervals for linear model\n",
    "df_pred = df.dropna(subset=['od600', 'dcw_g_per_l']).copy()\n",
    "X_pred = df_pred[['od600']].values\n",
    "\n",
    "y_pred_linear = model_linear.predict(X_pred)\n",
    "\n",
    "# Standard error of prediction\n",
    "from scipy.stats import t\n",
    "n = len(X_clean)\n",
    "dof = n - 2\n",
    "t_crit = t.ppf(0.975, dof)  # 95% CI\n",
    "\n",
    "# Leverage (hat values)\n",
    "X_with_const = np.column_stack([np.ones(len(X_pred)), X_pred])\n",
    "X_clean_with_const = np.column_stack([np.ones(len(X_clean)), X_clean])\n",
    "hat = X_with_const @ np.linalg.inv(X_clean_with_const.T @ X_clean_with_const) @ X_with_const.T\n",
    "leverage = np.diag(hat)\n",
    "\n",
    "# Prediction interval\n",
    "se_pred = se_residuals * np.sqrt(1 + leverage)\n",
    "ci_lower = y_pred_linear - t_crit * se_pred\n",
    "ci_upper = y_pred_linear + t_crit * se_pred\n",
    "\n",
    "df_pred['pred'] = y_pred_linear\n",
    "df_pred['ci_lower'] = ci_lower\n",
    "df_pred['ci_upper'] = ci_upper\n",
    "\n",
    "# Check coverage\n",
    "coverage = np.mean((df_pred['dcw_g_per_l'] >= df_pred['ci_lower']) & \n",
    "                    (df_pred['dcw_g_per_l'] <= df_pred['ci_upper']))\n",
    "\n",
    "print(f\"95% Prediction Interval Coverage: {coverage*100:.1f}%\")\n",
    "print(f\"Expected coverage: 95%\")\n",
    "print(f\"Status: {'✓ PASS' if coverage >= 0.90 else '✗ FAIL'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5803bf72",
   "metadata": {},
   "source": [
    "## 8. Model Comparison & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16137bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive comparison plot\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: OD600 vs Biomass with both models\n",
    "od600_range = np.linspace(df_pred['od600'].min(), df_pred['od600'].max(), 100).reshape(-1, 1)\n",
    "dcw_linear_range = model_linear.predict(od600_range)\n",
    "\n",
    "axes[0, 0].scatter(df_pred['od600'], df_pred['dcw_g_per_l'], alpha=0.6, s=80, label='Measured', color='blue')\n",
    "axes[0, 0].plot(od600_range, dcw_linear_range, 'r-', linewidth=2, label='Linear Model')\n",
    "axes[0, 0].fill_between(od600_range.flatten(), \n",
    "                         model_linear.predict(od600_range) - t_crit * se_residuals,\n",
    "                         model_linear.predict(od600_range) + t_crit * se_residuals,\n",
    "                         alpha=0.2, color='red', label='95% PI')\n",
    "axes[0, 0].set_xlabel('OD600')\n",
    "axes[0, 0].set_ylabel('Biomass (g/L)')\n",
    "axes[0, 0].set_title('Linear Calibration Model')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Residuals\n",
    "axes[0, 1].scatter(y_pred_linear, residuals, alpha=0.6, s=80, color='green')\n",
    "axes[0, 1].axhline(y=0, color='black', linestyle='--')\n",
    "axes[0, 1].axhline(y=2*se_residuals, color='red', linestyle=':', label='±2SE')\n",
    "axes[0, 1].axhline(y=-2*se_residuals, color='red', linestyle=':')\n",
    "axes[0, 1].set_xlabel('Predicted Biomass (g/L)')\n",
    "axes[0, 1].set_ylabel('Residuals (g/L)')\n",
    "axes[0, 1].set_title('Residual Plot')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Q-Q plot\n",
    "stats.probplot(residuals, dist=\"norm\", plot=axes[1, 0])\n",
    "axes[1, 0].set_title('Q-Q Plot (Normality Check)')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Model comparison metrics\n",
    "models = ['Linear', 'Gaussian\\nProcess']\n",
    "r2_scores = [r2, r2_gp]\n",
    "rmse_scores = [rmse, rmse_gp]\n",
    "\n",
    "ax4a = axes[1, 1]\n",
    "x_pos = np.arange(len(models))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax4a.bar(x_pos - width/2, r2_scores, width, label='R²', color='steelblue')\n",
    "ax4a.set_ylabel('R² Score', color='steelblue')\n",
    "ax4a.set_ylim([0.85, 1.0])\n",
    "ax4a.tick_params(axis='y', labelcolor='steelblue')\n",
    "\n",
    "ax4b = ax4a.twinx()\n",
    "bars2 = ax4b.bar(x_pos + width/2, rmse_scores, width, label='RMSE', color='coral')\n",
    "ax4b.set_ylabel('RMSE (g/L)', color='coral')\n",
    "ax4b.tick_params(axis='y', labelcolor='coral')\n",
    "\n",
    "ax4a.set_xticks(x_pos)\n",
    "ax4a.set_xticklabels(models)\n",
    "ax4a.set_title('Model Comparison')\n",
    "ax4a.axhline(y=0.90, color='green', linestyle='--', alpha=0.5, label='R² threshold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('resources/notebooks/model-comparison.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Model comparison plots generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61408f97",
   "metadata": {},
   "source": [
    "## 9. Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2040b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect anomalies using multiple methods\n",
    "anomalies = []\n",
    "\n",
    "# Method 1: Rate-of-change filter\n",
    "max_growth_rate = df['dod_dt'].quantile(0.95)\n",
    "min_growth_rate = df['dod_dt'].quantile(0.05)\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    if pd.notna(row['dod_dt']):\n",
    "        if row['dod_dt'] > max_growth_rate * 1.5 or row['dod_dt'] < min_growth_rate * 0.5:\n",
    "            anomalies.append({\n",
    "                'index': idx,\n",
    "                'time': row['elapsed_hours'],\n",
    "                'method': 'Rate-of-change',\n",
    "                'value': row['dod_dt']\n",
    "            })\n",
    "\n",
    "# Method 2: Residual-based detection (using linear model)\n",
    "if len(anomalies) == 0:\n",
    "    residual_threshold = 3 * se_residuals\n",
    "    for idx, row in df_pred.iterrows():\n",
    "        if abs(row['dcw_g_per_l'] - row['pred']) > residual_threshold:\n",
    "            anomalies.append({\n",
    "                'index': idx,\n",
    "                'time': row['elapsed_hours'],\n",
    "                'method': 'Residual',\n",
    "                'value': row['dcw_g_per_l'] - row['pred']\n",
    "            })\n",
    "\n",
    "print(f\"Anomalies detected: {len(anomalies)}\")\n",
    "if anomalies:\n",
    "    for anom in anomalies:\n",
    "        print(f\"  - {anom['method']} at t={anom['time']:.1f}h, value={anom['value']:.4f}\")\n",
    "else:\n",
    "    print(\"  No anomalies detected ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaf1284",
   "metadata": {},
   "source": [
    "## 10. Summary & Acceptance Decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffd83af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final report\n",
    "print(\"=\"*60)\n",
    "print(\"OD→BIOMASS CALIBRATION REPORT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nEXPERIMENT DETAILS:\")\n",
    "print(f\"  Strain: {exp['strain_id']}\")\n",
    "print(f\"  Medium: {exp['medium_type']}\")\n",
    "print(f\"  Temperature: {exp['temperature_celsius']}°C\")\n",
    "print(f\"  Duration: {df['elapsed_hours'].max():.1f} hours\")\n",
    "print(f\"  Samples: {len(df)} time points\")\n",
    "\n",
    "print(f\"\\nLINEAR MODEL RESULTS:\")\n",
    "print(f\"  Equation: DCW = {intercept:.4f} + {slope:.4f} × OD600\")\n",
    "print(f\"  R² Score: {r2:.4f}\")\n",
    "print(f\"  RMSE: {rmse:.4f} g/L\")\n",
    "print(f\"  MAE: {mae:.4f} g/L\")\n",
    "\n",
    "print(f\"\\nGAUSSIAN PROCESS RESULTS:\")\n",
    "print(f\"  R² Score: {r2_gp:.4f}\")\n",
    "print(f\"  RMSE: {rmse_gp:.4f} g/L\")\n",
    "print(f\"  Mean Uncertainty: ±{y_std_gp.mean():.4f} g/L\")\n",
    "\n",
    "print(f\"\\nACCEPTANCE CRITERIA:\")\n",
    "criteria = [\n",
    "    ('Linear R² ≥ 0.90', r2 >= 0.90),\n",
    "    ('Linear RMSE < 0.15 g/L', rmse < 0.15),\n",
    "    ('GP R² ≥ 0.92', r2_gp >= 0.92),\n",
    "    ('Prediction Interval Coverage ≥ 90%', coverage >= 0.90),\n",
    "    ('No critical anomalies', len(anomalies) == 0)\n",
    "]\n",
    "\n",
    "passed = 0\n",
    "for criterion, result in criteria:\n",
    "    status = '✓ PASS' if result else '✗ FAIL'\n",
    "    print(f\"  {criterion}: {status}\")\n",
    "    if result:\n",
    "        passed += 1\n",
    "\n",
    "print(f\"\\nOVERALL DECISION: {passed}/{len(criteria)} criteria met\")\n",
    "if passed == len(criteria):\n",
    "    print(\"STATUS: ✓ APPROVED - Model ready for deployment\")\n",
    "else:\n",
    "    print(\"STATUS: ✗ HOLD - Address failures before deployment\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
