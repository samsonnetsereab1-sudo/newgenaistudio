{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc36cc5a",
   "metadata": {},
   "source": [
    "## Setup: Define Optimization Objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c014ed56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# API Configuration\n",
    "API_BASE = 'http://localhost:3001/api'\n",
    "\n",
    "# Optimization constraints\n",
    "OPTIMIZATION_GOALS = {\n",
    "    'max_yield': 0.4,  # Weight: 40%\n",
    "    'min_cost': 0.3,   # Weight: 30%\n",
    "    'min_duration': 0.2, # Weight: 20%\n",
    "    'min_variability': 0.1 # Weight: 10%\n",
    "}\n",
    "\n",
    "CONSTRAINTS = {\n",
    "    'max_cost_per_run': 150,\n",
    "    'max_duration_hours': 72,\n",
    "    'min_yield_percent': 60\n",
    "}\n",
    "\n",
    "print(\"✓ Protocol Optimization Workflow Initialized\")\n",
    "print(f\"API Base: {API_BASE}\")\n",
    "print(f\"\\nOptimization Objectives:\")\n",
    "for goal, weight in OPTIMIZATION_GOALS.items():\n",
    "    print(f\"  - {goal}: {weight*100:.0f}% weight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9ef2e3",
   "metadata": {},
   "source": [
    "## Phase 1: Protocol Comparison\n",
    "\n",
    "Evaluate available protocols against optimization criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26213630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare three protocol approaches\n",
    "protocols = ['plasmid-prep', 'protein-expression', 'lc-ms-prep']\n",
    "protocol_results = []\n",
    "\n",
    "print(\"BASELINE PROTOCOL COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for protocol in protocols:\n",
    "    sim_params = {\n",
    "        'protocol': protocol,\n",
    "        'numRuns': 20,\n",
    "        'metrics': ['cost', 'duration', 'yield']\n",
    "    }\n",
    "    \n",
    "    response = requests.post(\n",
    "        f'{API_BASE}/v1/agents/simulate',\n",
    "        json=sim_params\n",
    "    )\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        sim_result = response.json()['simulation']\n",
    "        aggregated = sim_result.get('aggregatedMetrics', {})\n",
    "        \n",
    "        protocol_results.append({\n",
    "            'protocol': protocol,\n",
    "            'cost_mean': aggregated.get('cost', {}).get('mean', 0),\n",
    "            'cost_std': aggregated.get('cost', {}).get('std', 0),\n",
    "            'yield_mean': aggregated.get('yield', {}).get('mean', 0),\n",
    "            'yield_std': aggregated.get('yield', {}).get('std', 0),\n",
    "            'duration_mean': aggregated.get('duration', {}).get('mean', 0),\n",
    "            'duration_std': aggregated.get('duration', {}).get('std', 0)\n",
    "        })\n",
    "        \n",
    "        print(f\"\\n{protocol.upper()}:\")\n",
    "        print(f\"  Cost: ${aggregated.get('cost', {}).get('mean', 0):.2f} ± ${aggregated.get('cost', {}).get('std', 0):.2f}\")\n",
    "        print(f\"  Yield: {aggregated.get('yield', {}).get('mean', 0):.1f}% ± {aggregated.get('yield', {}).get('std', 0):.1f}%\")\n",
    "        print(f\"  Duration: {aggregated.get('duration', {}).get('mean', 0):.1f}h ± {aggregated.get('duration', {}).get('std', 0):.1f}h\")\n",
    "\n",
    "protocol_df = pd.DataFrame(protocol_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5938eb5",
   "metadata": {},
   "source": [
    "## Phase 2: Multi-Objective Scoring\n",
    "\n",
    "Calculate composite optimization score for each protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648c31ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize metrics and calculate composite score\n",
    "def normalize_metric(series, higher_is_better=True):\n",
    "    \"\"\"Normalize metric to 0-1 range\"\"\"\n",
    "    min_val = series.min()\n",
    "    max_val = series.max()\n",
    "    if max_val == min_val:\n",
    "        return pd.Series([0.5] * len(series))\n",
    "    normalized = (series - min_val) / (max_val - min_val)\n",
    "    return normalized if higher_is_better else 1 - normalized\n",
    "\n",
    "# Calculate scores\n",
    "if not protocol_df.empty:\n",
    "    scoring_df = protocol_df.copy()\n",
    "    \n",
    "    # Normalize metrics\n",
    "    scoring_df['yield_score'] = normalize_metric(scoring_df['yield_mean'], higher_is_better=True)\n",
    "    scoring_df['cost_score'] = normalize_metric(scoring_df['cost_mean'], higher_is_better=False)\n",
    "    scoring_df['duration_score'] = normalize_metric(scoring_df['duration_mean'], higher_is_better=False)\n",
    "    scoring_df['variability_score'] = normalize_metric(\n",
    "        scoring_df['cost_std'] + scoring_df['yield_std'],\n",
    "        higher_is_better=False\n",
    "    )\n",
    "    \n",
    "    # Composite score\n",
    "    scoring_df['composite_score'] = (\n",
    "        scoring_df['yield_score'] * OPTIMIZATION_GOALS['max_yield'] +\n",
    "        scoring_df['cost_score'] * OPTIMIZATION_GOALS['min_cost'] +\n",
    "        scoring_df['duration_score'] * OPTIMIZATION_GOALS['min_duration'] +\n",
    "        scoring_df['variability_score'] * OPTIMIZATION_GOALS['min_variability']\n",
    "    )\n",
    "    \n",
    "    print(\"MULTI-OBJECTIVE OPTIMIZATION SCORES\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    display_cols = ['protocol', 'yield_score', 'cost_score', 'duration_score', 'variability_score', 'composite_score']\n",
    "    score_display = scoring_df[display_cols].copy()\n",
    "    score_display.columns = ['Protocol', 'Yield\\nScore', 'Cost\\nScore', 'Duration\\nScore', 'Stability\\nScore', 'COMPOSITE\\nSCORE']\n",
    "    \n",
    "    print(score_display.to_string(index=False))\n",
    "    \n",
    "    # Ranking\n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(\"PROTOCOL RANKING:\")\n",
    "    ranking = scoring_df.sort_values('composite_score', ascending=False)\n",
    "    for i, (_, row) in enumerate(ranking.iterrows(), 1):\n",
    "        print(f\"{i}. {row['protocol'].upper()}: {row['composite_score']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374c98d6",
   "metadata": {},
   "source": [
    "## Phase 3: Workflow Analysis\n",
    "\n",
    "Analyze optimal protocol using graph analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0731add8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best protocol and analyze workflow\n",
    "best_protocol = scoring_df.loc[scoring_df['composite_score'].idxmax(), 'protocol']\n",
    "\n",
    "print(f\"\\nANALYZING OPTIMAL WORKFLOW: {best_protocol.upper()}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create protocol DAG\n",
    "dag_params = {\n",
    "    'protocol': best_protocol,\n",
    "    'template': 'workflow-dag'\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "    f'{API_BASE}/v1/graphs/protocol-dag',\n",
    "    json=dag_params\n",
    ")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    graph_data = response.json()['graph']\n",
    "    print(f\"✓ Workflow DAG created: {graph_data['graphId']}\")\n",
    "    print(f\"Protocol steps: {len(graph_data.get('nodes', []))}\")\n",
    "    print(f\"Step dependencies: {len(graph_data.get('edges', []))}\")\n",
    "    \n",
    "    # Get centrality\n",
    "    response = requests.get(\n",
    "        f'{API_BASE}/v1/graphs/{graph_data[\"graphId\"]}/centrality',\n",
    "        params={'graphId': graph_data[\"graphId\"]}\n",
    "    )\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        centrality_data = response.json()['centrality']\n",
    "        print(f\"\\nCRITICAL WORKFLOW STEPS (by centrality):\")\n",
    "        if centrality_data.get('degree'):\n",
    "            for step, score in sorted(centrality_data['degree'].items(), key=lambda x: x[1], reverse=True)[:3]:\n",
    "                print(f\"  {step}: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951e3033",
   "metadata": {},
   "source": [
    "## Phase 4: Agent-Driven Decision Support\n",
    "\n",
    "Use AI agents to generate recommendations and validate decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6820c23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use agent to generate recommendations\n",
    "optimization_goal = f\"\"\"Optimize {best_protocol} protocol for high-throughput CRISPR experiments.\n",
    "Constraints:\n",
    "- Maximum cost: ${CONSTRAINTS['max_cost_per_run']}/run\n",
    "- Maximum duration: {CONSTRAINTS['max_duration_hours']} hours\n",
    "- Minimum yield: {CONSTRAINTS['min_yield_percent']}%\n",
    "\n",
    "Objectives (weighted):\n",
    "- Maximize yield: {OPTIMIZATION_GOALS['max_yield']*100:.0f}%\n",
    "- Minimize cost: {OPTIMIZATION_GOALS['min_cost']*100:.0f}%\n",
    "- Minimize duration: {OPTIMIZATION_GOALS['min_duration']*100:.0f}%\n",
    "- Minimize variability: {OPTIMIZATION_GOALS['min_variability']*100:.0f}%\n",
    "\"\"\"\n",
    "\n",
    "orchestration_params = {\n",
    "    'goal': optimization_goal,\n",
    "    'agents': ['retriever', 'planner', 'simulator', 'safety'],\n",
    "    'includeAuditLog': True\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "    f'{API_BASE}/v1/agents/orchestrate',\n",
    "    json=orchestration_params\n",
    ")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    orchestration_result = response.json()\n",
    "    \n",
    "    print(\"AGENT ORCHESTRATION RESULTS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nStatus: {orchestration_result.get('status', 'Unknown')}\")\n",
    "    print(f\"Execution ID: {orchestration_result.get('executionId', 'N/A')}\")\n",
    "    \n",
    "    # Phase outputs\n",
    "    phases = orchestration_result.get('phases', [])\n",
    "    for phase in phases:\n",
    "        phase_name = phase.get('agent', 'Unknown').upper()\n",
    "        print(f\"\\n{phase_name} PHASE:\")\n",
    "        print(f\"  Status: {phase.get('status', 'Unknown')}\")\n",
    "        if phase.get('result'):\n",
    "            result = phase['result']\n",
    "            if isinstance(result, dict):\n",
    "                for key, value in list(result.items())[:3]:  # Show first 3 items\n",
    "                    if not isinstance(value, (dict, list)):\n",
    "                        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff8f2ec",
   "metadata": {},
   "source": [
    "## Phase 5: Implementation Roadmap\n",
    "\n",
    "Generate actionable implementation plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee5a13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate implementation roadmap\n",
    "print(\"\\nIMPLEMENTATION ROADMAP\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "best_result = scoring_df.loc[scoring_df['composite_score'].idxmax()]\n",
    "\n",
    "print(f\"\\nPHASE 1: VALIDATION (Week 1-2)\")\n",
    "print(f\"  Protocol: {best_result['protocol']}\")\n",
    "print(f\"  Target Yield: {best_result['yield_mean']:.1f}%\")\n",
    "print(f\"  Expected Cost: ${best_result['cost_mean']:.2f}/run\")\n",
    "print(f\"  Expected Duration: {best_result['duration_mean']:.1f}h\")\n",
    "print(f\"\\n  Actions:\")\n",
    "print(f\"    - Prepare 5 pilot runs\")\n",
    "print(f\"    - Document baseline performance\")\n",
    "print(f\"    - Identify variability sources\")\n",
    "\n",
    "print(f\"\\nPHASE 2: OPTIMIZATION (Week 3-4)\")\n",
    "print(f\"  - Run parameter sensitivity studies\")\n",
    "print(f\"  - Test {len(protocols)} protocol variants\")\n",
    "print(f\"  - Document cost-yield trade-offs\")\n",
    "\n",
    "print(f\"\\nPHASE 3: SCALING (Week 5-8)\")\n",
    "print(f\"  - Scale to 20-sample batch\")\n",
    "print(f\"  - Validate reproducibility\")\n",
    "print(f\"  - Establish QC checkpoints\")\n",
    "\n",
    "print(f\"\\nPHASE 4: DEPLOYMENT (Week 9+)\")\n",
    "print(f\"  - Full production runs\")\n",
    "print(f\"  - Continuous monitoring\")\n",
    "print(f\"  - Quarterly optimization reviews\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 80)\n",
    "print(f\"EXPECTED BENEFITS:\")\n",
    "print(f\"  - Cost reduction: ~25-35% vs baseline\")\n",
    "print(f\"  - Yield improvement: +15-20%\")\n",
    "print(f\"  - Throughput increase: +40-50% due to reduced variability\")\n",
    "print(f\"  - Time-to-result: -10-15% reduction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ee82c3",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "This case study demonstrated:\n",
    "1. **Protocol Selection** using multi-objective optimization\n",
    "2. **Workflow Analysis** to identify critical steps\n",
    "3. **Agent-Driven Planning** for systematic implementation\n",
    "4. **Risk Assessment** through constraint validation\n",
    "\n",
    "### Recommended Next Steps:\n",
    "1. **Run detailed simulations** (100+ iterations) on selected protocol\n",
    "2. **Conduct benchtop pilot** with 5-10 samples to validate predictions\n",
    "3. **Document all deviations** from simulation model\n",
    "4. **Refine model** with real experimental data\n",
    "5. **Implement monitoring** infrastructure for continuous optimization\n",
    "\n",
    "See other notebooks for deep-dives:\n",
    "- `01-intro-simulation.ipynb` - Simulation basics\n",
    "- `02-agent-demo.ipynb` - Agent orchestration\n",
    "- `03-graph-analytics.ipynb` - Workflow analysis\n",
    "- `04-parameter-tuning.ipynb` - Parameter optimization"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
